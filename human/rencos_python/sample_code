@ datastore rpc .  positional ( 7 ) def get indexes ( namespace = '' , offset =  None  , limit = 20 , start index name =  None  , include start index =  True  , index name prefix =  None  , fetch schema =  False  , deadline =  None  , ** kwargs ) : return get indexes async ( namespace , offset , limit , start index name , include start index , index name prefix , fetch schema , deadline = deadline , ** kwargs ) . get result ( ) 
def deserializers ( ** deserializers ) : def decorator ( func ) : if ( not hasattr ( func , 'wsgi deserializers' ) ) : func . wsgi deserializers = { } func . wsgi deserializers . update ( deserializers ) return func return decorator 
def  get id token user ( token , audiences , allowed client ids , time now , cache ) : try : parsed token =  verify signed jwt with certs ( token , time now , cache ) except   App  Identity  Error  as e : logging . warning ( 'id token  verification  failed:  %s' , e ) return  None  except : logging . warning ( 'id token  verification  failed.' ) return  None  if  verify parsed token ( parsed token , audiences , allowed client ids ) : email = parsed token [ 'email' ] return users .  User  ( email ) 
def  convert to prover9 ( expression ) : if isinstance ( expression ,  Exists  Expression  ) : return ( ( ( 'exists  ' + str ( expression . variable ) ) + '  ' ) +  convert to prover9 ( expression . term ) ) elif isinstance ( expression ,  All  Expression  ) : return ( ( ( 'all  ' + str ( expression . variable ) ) + '  ' ) +  convert to prover9 ( expression . term ) ) elif isinstance ( expression ,  Negated  Expression  ) : return ( ( '-(' +  convert to prover9 ( expression . term ) ) + ')' ) elif isinstance ( expression ,  And  Expression  ) : return ( ( ( ( '(' +  convert to prover9 ( expression . first ) ) + '  &  ' ) +  convert to prover9 ( expression . second ) ) + ')' ) elif isinstance ( expression ,  Or  Expression  ) : return ( ( ( ( '(' +  convert to prover9 ( expression . first ) ) + '  |  ' ) +  convert to prover9 ( expression . second ) ) + ')' ) elif isinstance ( expression ,  Imp  Expression  ) : return ( ( ( ( '(' +  convert to prover9 ( expression . first ) ) + '  ->  ' ) +  convert to prover9 ( expression . second ) ) + ')' ) elif isinstance ( expression ,  Iff  Expression  ) : return ( ( ( ( '(' +  convert to prover9 ( expression . first ) ) + '  <->  ' ) +  convert to prover9 ( expression . second ) ) + ')' ) elif isinstance ( expression ,  Equality  Expression  ) : return ( ( ( ( '(' +  convert to prover9 ( expression . first ) ) + '  =  ' ) +  convert to prover9 ( expression . second ) ) + ')' ) else : return str ( expression ) 
def htmlunquote ( text ) : text = text . replace ( u'&quot;' , u'"' ) text = text . replace ( u'&#39;' , u"'" ) text = text . replace ( u'&gt;' , u'>' ) text = text . replace ( u'&lt;' , u'<' ) text = text . replace ( u'&amp;' , u'&' ) return text 
def get enrollment attributes ( user id , course id ) : return  ENROLLMENT ATTRIBUTES 
def agent service deregister ( consul url =  None  , serviceid =  None  ) : ret = { } data = { } if ( not consul url ) : consul url =  get config ( ) if ( not consul url ) : log . error ( ' No    Consul   URL  found.' ) ret [ 'message' ] = ' No    Consul   URL  found.' ret [ 'res' ] =  False  return ret if ( not serviceid ) : raise  Salt  Invocation  Error  ( ' Required   argument  "serviceid"  is  missing.' ) function = 'agent/service/deregister/{0}' . format ( serviceid ) res =  query ( consul url = consul url , function = function , method = 'PUT' , data = data ) if res [ 'res' ] : ret [ 'res' ] =  True  ret [ 'message' ] = ' Service   {0}  removed  from  agent.' . format ( serviceid ) else : ret [ 'res' ] =  False  ret [ 'message' ] = ' Unable   to  remove  service  {0}.' . format ( serviceid ) return ret 
def get subtitle path ( video path , language , multi ) : if ( not os . path . exists ( video path ) ) : path = os . path . splitext ( os . path . basename ( video path ) ) [ 0 ] else : path = os . path . splitext ( video path ) [ 0 ] if ( multi and language ) : return ( path + ( '.%s%s' % ( language . alpha2 , EXTENSIONS [ 0 ] ) ) ) return ( path + ( '%s' % EXTENSIONS [ 0 ] ) ) 
def check resource update ( rsrc , template id , resource data , engine id , stack , msg queue ) : check message = functools . partial (  check for message , msg queue ) if ( rsrc . action == resource .  Resource  . INIT ) : rsrc . create convergence ( template id , resource data , engine id , stack . time remaining ( ) , check message ) else : rsrc . update convergence ( template id , resource data , engine id , stack . time remaining ( ) , stack , check message ) 
def field ( name , type = STRING , ** kwargs ) : ( default , index , optional ) = ( kwargs . get ( 'default' , ( ( ( type == DATE ) and NOW ) or  None  ) ) , kwargs . get ( 'index' ,  False  ) , kwargs . get ( 'optional' ,  True  ) ) if ( type == STRING ) : type = STRING ( ) if ( type == FLOAT ) : type = 'real' if ( type == BOOLEAN ) : type = 'tinyint(1)' if ( type == DATE ) : type = 'timestamp' if ( str ( index ) in '01' ) : index = bool ( int ( index ) ) if ( str ( optional ) in '01' ) : optional = bool ( int ( optional ) ) return ( name , type , default , index , optional ) 
def sew messages and reactions ( messages , reactions ) : for message in messages : message [ 'reactions' ] = [ ] converted messages = { message [ 'id' ] : message for message in messages } for reaction in reactions : converted messages [ reaction [ 'message id' ] ] [ 'reactions' ] . append ( reaction ) return list ( converted messages . values ( ) ) 
def show state usage ( queue =  False  , ** kwargs ) : conflict =  check queue ( queue , kwargs ) if ( conflict is not  None  ) : return conflict pillar = kwargs . get ( 'pillar' ) pillar enc = kwargs . get ( 'pillar enc' ) if ( ( pillar enc is  None  ) and ( pillar is not  None  ) and ( not isinstance ( pillar , dict ) ) ) : raise  Salt  Invocation  Error  ( ' Pillar   data  must  be  formatted  as  a  dictionary,  unless  pillar enc  is  specified.' ) st  = salt . state .  High  State  (   opts   , pillar , pillar enc = pillar enc ) st  . push active ( ) try : ret = st  . compile state usage ( ) finally : st  . pop active ( )  set retcode ( ret ) return ret 
def  sympifyit ( arg , retval =  None  ) : def deco ( func ) : return   sympifyit ( func , arg , retval ) return deco 
def list add ( t ) : ( owner , slug ) = get slug ( ) user name = raw input ( light magenta ( ' Give   me  name  of  the  newbie:  ' , rl =  True  ) ) if user name . startswith ( '@' ) : user name = user name [ 1 : ] try : t . lists . members . create ( slug = slug , owner screen name = owner , screen name = user name ) print Nicely  ( green ( ' Added .' ) ) except : debug option ( ) print Nicely  ( light magenta ( "I'm  sorry  we  can  not  add  him/her." ) ) 
def  Auto  Legend  ( chart ) : chart .  show legend =  False  labels = [ ] for series in chart . data : if ( series . label is  None  ) : labels . append ( '' ) else : labels . append ( series . label ) chart .  show legend =  True  if chart .  show legend : chart .  legend labels = labels 
def pretty ( expr ) : return xpretty ( expr , use unicode =  False  , wrap line =  False  ) 
def fixed points ( G ) : return [ n for n in G if ( G . out degree ( n ) == 0 ) ] 
def deploy alert select recipients ( r , ** attr ) : alert id = r . id if ( ( r . representation not in ( 'html' , 'aadata' ) ) or ( not alert id ) or ( not r . component ) ) : r . error ( 405 , current . ERROR . BAD METHOD ) authorised = current . auth . s3 has permission ( 'update' , 'deploy alert' , record id = alert id ) if ( not authorised ) : r . unauthorised ( ) T = current . T s3db = current . s3db response = current . response s3 = response . s3 member query = ( s3 . member query or ( FS ( 'application.active' ) !=  None  ) ) if ( r . http == 'POST' ) : added = 0 post vars = r . post vars if all ( [ ( n in post vars ) for n in ( 'select' , 'selected' , 'mode' ) ] ) : selected = post vars . selected if selected : selected = selected . split ( ',' ) else : selected = [ ] db = current . db if ( post vars . mode == ' Exclusive ' ) : if ( 'filterURL' in post vars ) : filters = S3URL Query  . parse url ( post vars . filterURL ) else : filters =  None  query = ( member query & ( ~ FS ( 'id' ) . belongs ( selected ) ) ) hresource = s3db . resource ( 'hrm human resource' , filter = query , vars = filters ) rows = hresource . select ( [ 'id' ] , as rows =  True  ) selected = [ str ( row . id ) for row in rows ] rtable = s3db . deploy alert recipient query = ( ( ( rtable . alert id == alert id ) & rtable . human resource id . belongs ( selected ) ) & ( rtable . deleted !=  True  ) ) rows = db ( query ) . select ( rtable . human resource id ) skip = set ( ( row . human resource id for row in rows ) ) for human resource id in selected : try : hr id = int ( human resource id . strip ( ) ) except  Value  Error  : continue if ( hr id in skip ) : continue rtable . insert ( alert id = alert id , human resource id = human resource id ) added += 1 if ( not selected ) : response . warning = T ( ' No    Recipients    Selected !' ) else : response . confirmation = ( T ( '%(number)s   Recipients   added  to   Alert ' ) % dict ( number = added ) ) get vars = ( r . get vars or { } ) representation = r . representation settings = current . deployment settings resource = s3db . resource ( 'hrm human resource' , filter = member query , vars = r . get vars ) filter widgets = deploy member filters ( status =  True  ) if current . deployment settings . get deploy select ratings ( ) : rating opts = { 1 : 1 , 2 : 2 , 3 : 3 , 4 : 4 } filter widgets . extend ( ( S3 Options  Filter  ( 'application.status' , label = T ( ' Category ' ) , options = { 1 : 'I' , 2 : 'II' , 3 : 'III' , 4 : 'IV' , 5 : 'V' } , cols = 5 ) , S3 Options  Filter  ( 'training.grade' , label = T ( ' Training    Grade ' ) , options = rating opts , cols = 4 ) , S3 Options  Filter  ( 'appraisal.rating' , label = T ( ' Deployment    Rating ' ) , options = rating opts , cols = 4 ) ) ) if ( filter widgets and ( representation == 'html' ) ) : resource . configure ( filter widgets = filter widgets ) S3 Filter  Form  . apply filter defaults ( r , resource ) list fields = [ 'id' , 'person id' , 'job title id' , 'organisation id' ] totalrows = resource . count ( ) if ( 'page Length ' in get vars ) : display length = get vars [ 'page Length ' ] if ( display length == ' None ' ) : display length =  None  else : display length = int ( display length ) else : display length = 25 if display length : limit = ( 4 * display length ) else : limit =  None  if ( r . representation != 'aadata' ) : get vars = dict ( get vars ) dt sorting = { 'i Sorting  Cols ' : '1' , 'b Sortable  0' : 'false' , 'i Sort  Col  0' : '1' , 's Sort  Dir  0' : 'desc' } get vars . update ( dt sorting ) ( filter , orderby , left ) = resource . datatable filter ( list fields , get vars ) resource . add filter ( filter ) resource . add filter ( s3 . filter ) data = resource . select ( list fields , start = 0 , limit = limit , orderby = orderby , left = left , count =  True  , represent =  True  ) filteredrows = data . numrows dt = S3 Data  Table  ( data . rfields , data . rows , orderby = orderby ) dt id = 'datatable' dt bulk actions = [ ( T ( ' Select   as   Recipients ' ) , 'select' ) ] if ( representation == 'html' ) : resource . configure ( deletable =  False  ) s3 . no formats =  True  items = dt . html ( totalrows , filteredrows , dt id , dt ajax url = r . url ( representation = 'aadata' ) , dt bulk actions = dt bulk actions , dt page Length  = display length , dt pagination = 'true' , dt searching = 'false' ) if filter widgets :  vars = resource . crud .  remove filters ( r . get vars ) filter submit url = r . url ( vars =  vars ) filter ajax url = URL ( f = 'human resource' , args = [ 'filter.options' ] , vars = { } ) get config = resource . get config filter clear = get config ( 'filter clear' ,  True  ) filter formstyle = get config ( 'filter formstyle' ,  None  ) filter submit = get config ( 'filter submit' ,  True  ) filter form = S3 Filter  Form  ( filter widgets , clear = filter clear , formstyle = filter formstyle , submit = filter submit , ajax =  True  , url = filter submit url , ajaxurl = filter ajax url ,  class = 'filter-form' ,  id = 'datatable-filter-form' ) fresource = s3db . resource ( resource . tablename ) alias = ( resource . alias if r . component else  None  ) ff = filter form . html ( fresource , r . get vars , target = 'datatable' , alias = alias ) else : ff = '' output = { 'items' : items , 'title' : T ( ' Select    Recipients ' ) , 'list filter form' : ff } if attr . get ( 'rheader' ) : rheader = attr [ 'rheader' ] ( r ) if rheader : output [ 'rheader' ] = rheader response . view = 'list filter.html' return output elif ( representation == 'aadata' ) : if ( 'draw' in get vars ) : echo = int ( get vars . draw ) else : echo =  None  items = dt . json ( totalrows , filteredrows , dt id , echo , dt bulk actions = dt bulk actions ) response . headers [ ' Content - Type ' ] = 'application/json' return items else : r . error ( 415 , current . ERROR . BAD FORMAT ) 
def convert password ( context , password ) : password = ( password or '' ) if ( six . PY3 and isinstance ( password , bytes ) ) : password = password . decode ( 'utf-8' ) meta = { } for i in range ( CHUNKS ) : meta [ ( 'password %d' % i ) ] = password [ : CHUNK LENGTH ] password = password [ CHUNK LENGTH : ] return meta 
def resolve ipv6 ( name , flags = 0 ) : waiter =  Waiter  ( ) core . dns resolve ipv6 ( name , flags , waiter . switch args ) ( result ,  type , ttl , addrs ) = waiter . get ( ) if ( result != core . DNS ERR NONE ) : raise DNS Error  ( result ) return ( ttl , addrs ) 
def  offset or limit clause asint ( clause , attrname ) : if ( clause is  None  ) : return  None  try : value = clause .  limit offset value except  Attribute  Error  : raise exc .  Compile  Error  ( ( ' This   SELECT  structure  does  not  use  a  simple  integer  value  for  %s' % attrname ) ) else : return util . asint ( value ) 
def scheduled backup ( older than = 6 , ignore files =  False  , backup path db =  None  , backup path files =  None  , backup path private files =  None  , force =  False  ) : odb = new backup ( older than , ignore files , backup path db = backup path db , backup path files = backup path files , force = force ) return odb 
def find flaky tests ( suites ) : for test in  iter tests ( suites ) : annotation = get flaky annotation ( test ) if annotation : ( yield ( test , annotation ) ) 
def   virtual   ( ) : if ( not salt . utils . is sunos ( ) ) : return (  False  , ' The   at  module  could  not  be  loaded:  unsupported  platform' ) if ( ( not salt . utils . which ( 'at' ) ) or ( not salt . utils . which ( 'atq' ) ) or ( not salt . utils . which ( 'atrm' ) ) ) : return (  False  , ' The   at  module  could  not  be  loaded:  at  command  not  found' ) return   virtualname   
def env file ( registry , xml parent , data ) : eib = XML .  Sub  Element  ( xml parent , 'hudson.plugins.envfile. Env  File  Build  Wrapper ' ) jenkins jobs . modules . base . add nonblank xml subelement ( eib , 'file Path ' , data . get ( 'properties-file' ) ) 
def unbroadcast ( x , * axes ) : rval =  Rebroadcast  ( * [ ( axis ,  False  ) for axis in axes ] ) ( x ) return theano . tensor . opt . apply rebroadcast opt ( rval ) 
def retrieve flags ( flag dict , flag filter ) : return [ ( f [ 0 ] , f [ 1 ] ) for f in list ( flag dict . items ( ) ) if ( isinstance ( f [ 0 ] , ( str , bytes ) ) and f [ 0 ] . startswith ( flag filter ) ) ] 
def get pid ( ) : if ( not os . path . isfile ( PID FILE ) ) : if os . path . isfile ( STARTUP LOCK ) : try : ( pid , port ) = read pid file ( STARTUP LOCK ) if pid exists ( pid ) : raise  Not  Running  ( STATUS STARTING UP ) else : raise  Not  Running  ( STATUS FAILED TO START ) except  Type  Error  : raise  Not  Running  ( STATUS STOPPED ) raise  Not  Running  ( STATUS STOPPED ) try : ( pid , port ) = read pid file ( PID FILE ) except (  Value  Error  , OS Error  ) : raise  Not  Running  ( STATUS PID FILE INVALID ) if ( not pid exists ( pid ) ) : if os . path . isfile ( STARTUP LOCK ) : raise  Not  Running  ( STATUS FAILED TO START ) raise  Not  Running  ( STATUS UNCLEAN SHUTDOWN ) listen port = ( port or DEFAULT LISTEN PORT ) conn = httplib . HTTP Connection  ( '127.0.0.1' , listen port , timeout = 3 ) try : conn . request ( 'GET' , PING URL ) response = conn . getresponse ( ) except ( timeout , socket . error ) : raise  Not  Running  ( STATUS NOT RESPONDING ) except ( httplib . HTTP Exception  , URL Error  ) : if os . path . isfile ( STARTUP LOCK ) : raise  Not  Running  ( STATUS STARTING UP ) raise  Not  Running  ( STATUS UNCLEAN SHUTDOWN ) if ( response . status == 404 ) : raise  Not  Running  ( STATUS UNKNOWN INSTANCE ) if ( response . status != 200 ) : raise  Not  Running  ( STATUS SERVER CONFIGURATION ERROR ) try : pid = int ( response . read ( ) ) except  Value  Error  : raise  Not  Running  ( STATUS UNKNOWN INSTANCE ) if ( pid == pid ) : return ( pid , LISTEN ADDRESS , listen port ) else : raise  Not  Running  ( STATUS UNKNOWN INSTANCE ) raise  Not  Running  ( STATUS UNKNOW ) 
def get issues list ( project , auth =  False  , ** params ) : params . setdefault ( 'state' , 'closed' ) url = 'https://api.github.com/repos/{project}/issues' . format ( project = project ) if auth : headers = make auth header ( ) else : headers =  None  pages = get paged request ( url , headers = headers , ** params ) return pages 
@ public def field ( symbols , domain , order = lex ) :  field =  Frac  Field  ( symbols , domain , order ) return ( (  field , ) +  field . gens ) 
def concatv ( * seqs ) : return concat ( seqs ) 
def read old config ( newconfig , changes , configfile ) : changesindex = { } for action in changes : if ( action [ 0 ] == 'moved' ) : ( option , oldgroup , newgroup ) = action [ 1 : ] changesindex . setdefault ( option , [ ] ) . append ( ( action [ 0 ] , oldgroup , newgroup ) ) continue if ( action [ 0 ] == 'renamed' ) : ( oldname , newname ) = action [ 1 : ] changesindex . setdefault ( newname , [ ] ) . append ( ( action [ 0 ] , oldname ) ) continue if ( action [ 0 ] == 'typechanged' ) : ( option , oldtype , newvalue ) = action [ 1 : ] changesindex . setdefault ( option , [ ] ) . append ( ( action [ 0 ] , oldtype , newvalue ) ) continue if ( action [ 1 ] in ( 'added' , 'removed' ) ) : continue raise  Exception  ( ( 'unknown  change  %s' % action [ 0 ] ) ) options = [ ] for ( optname , optdef ) in newconfig . options : for action in changesindex . pop ( optname , ( ) ) : if ( action [ 0 ] == 'moved' ) : ( oldgroup , newgroup ) = action [ 1 : ] optdef = optdef . copy ( ) optdef [ 'group' ] = oldgroup elif ( action [ 0 ] == 'renamed' ) : optname = action [ 1 ] elif ( action [ 0 ] == 'typechanged' ) : oldtype = action [ 1 ] optdef = optdef . copy ( ) optdef [ 'type' ] = oldtype options . append ( ( optname , optdef ) ) if changesindex : raise  Exception  ( ( 'unapplied  changes:  %s' % changesindex ) ) oldconfig =  Configuration  ( options = options , name = newconfig . name ) oldconfig . load file configuration ( configfile ) changes . reverse ( ) done = set ( ) for action in changes : if ( action [ 0 ] == 'renamed' ) : ( oldname , newname ) = action [ 1 : ] newconfig [ newname ] = oldconfig [ oldname ] done . add ( newname ) elif ( action [ 0 ] == 'typechanged' ) : ( optname , oldtype , newvalue ) = action [ 1 : ] newconfig [ optname ] = newvalue done . add ( optname ) for ( optname , optdef ) in newconfig . options : if ( optdef . get ( 'type' ) and ( not ( optname in done ) ) ) : newconfig . set option ( optname , oldconfig [ optname ] , optdict = optdef ) 
def print header ( line ) : header str = '=' header line = ( header str * len ( line ) ) print ( ( '\n' + header line ) ) print ( line ) print ( header line ) 
def create env ( ) : searchpath = list ( settings . JINJA2 TEMPLATE DIRS ) return  Environment  ( loader =  File  System  Loader  ( searchpath ) , auto reload = settings . TEMPLATE DEBUG , cache size = getattr ( settings , 'JINJA2 CACHE SIZE' , 50 ) , extensions = getattr ( settings , 'JINJA2 EXTENSIONS' , ( ) ) ) 
def  require post load hook ( action , * args , ** kwargs ) : if ( action == 'back' ) : return from twill import commands OUT = commands . OUT global ignore once global ignore always if ( ignore once or ignore always ) : ignore once =  False  return for what in  requirements : if ( what == 'success' ) : if DEBUG : print >> OUT , 'REQUIRING  success' commands . code ( 200 ) elif ( what == 'links ok' ) : from check links import check links ignore always =  True  if DEBUG : print >> OUT , 'REQUIRING  functioning  links' print >> OUT , '(already  visited:)' print '\n DCTB ' . join ( links visited . keys ( ) ) try : check links ( visited = links visited ) finally : ignore always =  False  
def test gemm unrolled ( ) : batch size = 100 rep size = 40 rng = numpy . random .  Random  State  ( [ 1 , 2 , 3 ] ) for num rounds in range ( 1 , 10 ) : W = sharedX ( rng . randn ( rep size , rep size ) , name = 'W' ) V = sharedX ( numpy . zeros ( ( batch size , rep size ) ) , name = 'V' ) H = sharedX ( numpy . zeros ( ( batch size , rep size ) ) , name = 'H' ) G = sharedX ( numpy . zeros ( ( batch size , rep size ) ) , name = 'G' ) init V = sharedX ( rng . uniform ( 0 , 1 , ( batch size , rep size ) ) , name = 'init V' ) init H = sharedX ( rng . uniform ( 0 , 1 , ( batch size , rep size ) ) , name = 'init H' ) cur V = V cur H = H def update V ( cur H ) : return T . nnet . sigmoid ( T . dot ( cur H , W . T ) ) def update H ( cur V ) : return T . nnet . sigmoid ( ( T . dot ( cur V , W ) + T . dot ( G , W . T ) ) ) for i in xrange ( num rounds ) : cur V = update V ( cur H ) cur H = update H ( cur V ) unrolled theano = theano . function ( [ ] , updates = [ ( V , cur V ) , ( H , cur H ) ] , name = 'unrolled theano' ) nb dot = sum ( [ 1 for node in unrolled theano . maker . fgraph . toposort ( ) if isinstance ( node . op , ( theano . tensor .  Dot  , theano . tensor . blas .  Dot 22 , theano . tensor . blas .  Gemm  ) ) ] ) assert ( nb dot == ( ( num rounds * 2 ) + 1 ) ) , nb dot unrolled theano ( ) 
def normalize language tag ( tag ) : tag = tag . lower ( ) . replace ( ' ' , '-' ) tag = re . sub ( '-([a-zA-Z0-9])-' , '-\\1 ' , tag ) taglist = [ ] subtags = [ subtag . replace ( ' ' , '-' ) for subtag in tag . split ( '-' ) ] base tag = [ subtags . pop ( 0 ) ] for n in range ( len ( subtags ) , 0 , ( - 1 ) ) : for tags in unique combinations ( subtags , n ) : taglist . append ( '-' . join ( ( base tag + tags ) ) ) taglist += base tag return taglist 
def get Widened  Loop  ( loop , loop List  , outset Loop  , radius ) : intersecting Within  Loops  = get Intersecting  Within  Loops  ( loop , loop List  , outset Loop  ) if ( len ( intersecting Within  Loops  ) < 1 ) : return loop loops Unified  = boolean solid . get Loops  Union  ( radius , [ [ loop ] , intersecting Within  Loops  ] ) if ( len ( loops Unified  ) < 1 ) : return loop return euclidean . get Largest  Loop  ( loops Unified  ) 
def get New  Repository  ( ) : return  Temperature  Repository  ( ) 
def message from bytes ( s , * args , ** kws ) : from email . parser import  Bytes  Parser  return  Bytes  Parser  ( * args , ** kws ) . parsebytes ( s ) 
def permission required ( permission name ) : def test ( user ) : return user . has perm ( permission name ) return user passes test ( test ) 
def linkify ( text , shorten =  False  , extra params = '' , require protocol =  False  , permitted protocols = [ 'http' , 'https' ] ) : if ( extra params and ( not callable ( extra params ) ) ) : extra params = ( '  ' + extra params . strip ( ) ) def make link ( m ) : url = m . group ( 1 ) proto = m . group ( 2 ) if ( require protocol and ( not proto ) ) : return url if ( proto and ( proto not in permitted protocols ) ) : return url href = m . group ( 1 ) if ( not proto ) : href = ( 'http://' + href ) if callable ( extra params ) : params = ( '  ' + extra params ( href ) . strip ( ) ) else : params = extra params max len = 30 if ( shorten and ( len ( url ) > max len ) ) : before clip = url if proto : proto len = ( ( len ( proto ) + 1 ) + len ( ( m . group ( 3 ) or '' ) ) ) else : proto len = 0 parts = url [ proto len : ] . split ( '/' ) if ( len ( parts ) > 1 ) : url = ( ( ( url [ : proto len ] + parts [ 0 ] ) + '/' ) + parts [ 1 ] [ : 8 ] . split ( '?' ) [ 0 ] . split ( '.' ) [ 0 ] ) if ( len ( url ) > ( max len * 1.5 ) ) : url = url [ : max len ] if ( url != before clip ) : amp = url . rfind ( '&' ) if ( amp > ( max len - 5 ) ) : url = url [ : amp ] url += '...' if ( len ( url ) >= len ( before clip ) ) : url = before clip else : params += ( '  title="%s"' % href ) return ( u ( '<a  href="%s"%s>%s</a>' ) % ( href , params , url ) ) text =  unicode ( xhtml escape ( text ) ) return  URL RE . sub ( make link , text ) 
def config ( settings ) : settings . base . prepopulate . append ( 'locations/PH' ) settings . gis . countries . append ( 'PH' ) settings . L10n . languages [ 'tl' ] = ' Tagalog ' settings . L10n . utc offset = '+0800' settings . L10n . default country code = 63 settings . fin . currencies [ 'PHP' ] = ' Philippine    Pesos ' settings . fin . currency default = 'PHP' 
def moment ( X , n , c = 0 , condition =  None  , ** kwargs ) : return expectation ( ( ( X - c ) ** n ) , condition , ** kwargs ) 
def inference deeper ( images , dropout =  False  ) : if ( FLAGS . dataset == 'mnist' ) : first conv shape = [ 3 , 3 , 1 , 96 ] else : first conv shape = [ 3 , 3 , 3 , 96 ] with tf . variable scope ( 'conv1' ) as scope : kernel =  variable with weight decay ( 'weights' , shape = first conv shape , stddev = 0.05 , wd = 0.0 ) conv = tf . nn . conv2d ( images , kernel , [ 1 , 1 , 1 , 1 ] , padding = 'SAME' ) biases =  variable on cpu ( 'biases' , [ 96 ] , tf . constant initializer ( 0.0 ) ) bias = tf . nn . bias add ( conv , biases ) conv1 = tf . nn . relu ( bias , name = scope . name ) with tf . variable scope ( 'conv2' ) as scope : kernel =  variable with weight decay ( 'weights' , shape = [ 3 , 3 , 96 , 96 ] , stddev = 0.05 , wd = 0.0 ) conv = tf . nn . conv2d ( conv1 , kernel , [ 1 , 1 , 1 , 1 ] , padding = 'SAME' ) biases =  variable on cpu ( 'biases' , [ 96 ] , tf . constant initializer ( 0.0 ) ) bias = tf . nn . bias add ( conv , biases ) conv2 = tf . nn . relu ( bias , name = scope . name ) with tf . variable scope ( 'conv3' ) as scope : kernel =  variable with weight decay ( 'weights' , shape = [ 3 , 3 , 96 , 96 ] , stddev = 0.05 , wd = 0.0 ) conv = tf . nn . conv2d ( conv2 , kernel , [ 1 , 2 , 2 , 1 ] , padding = 'SAME' ) biases =  variable on cpu ( 'biases' , [ 96 ] , tf . constant initializer ( 0.0 ) ) bias = tf . nn . bias add ( conv , biases ) conv3 = tf . nn . relu ( bias , name = scope . name ) if dropout : conv3 = tf . nn . dropout ( conv3 , 0.5 , seed = FLAGS . dropout seed ) with tf . variable scope ( 'conv4' ) as scope : kernel =  variable with weight decay ( 'weights' , shape = [ 3 , 3 , 96 , 192 ] , stddev = 0.05 , wd = 0.0 ) conv = tf . nn . conv2d ( conv3 , kernel , [ 1 , 1 , 1 , 1 ] , padding = 'SAME' ) biases =  variable on cpu ( 'biases' , [ 192 ] , tf . constant initializer ( 0.0 ) ) bias = tf . nn . bias add ( conv , biases ) conv4 = tf . nn . relu ( bias , name = scope . name ) with tf . variable scope ( 'conv5' ) as scope : kernel =  variable with weight decay ( 'weights' , shape = [ 3 , 3 , 192 , 192 ] , stddev = 0.05 , wd = 0.0 ) conv = tf . nn . conv2d ( conv4 , kernel , [ 1 , 1 , 1 , 1 ] , padding = 'SAME' ) biases =  variable on cpu ( 'biases' , [ 192 ] , tf . constant initializer ( 0.0 ) ) bias = tf . nn . bias add ( conv , biases ) conv5 = tf . nn . relu ( bias , name = scope . name ) with tf . variable scope ( 'conv6' ) as scope : kernel =  variable with weight decay ( 'weights' , shape = [ 3 , 3 , 192 , 192 ] , stddev = 0.05 , wd = 0.0 ) conv = tf . nn . conv2d ( conv5 , kernel , [ 1 , 2 , 2 , 1 ] , padding = 'SAME' ) biases =  variable on cpu ( 'biases' , [ 192 ] , tf . constant initializer ( 0.0 ) ) bias = tf . nn . bias add ( conv , biases ) conv6 = tf . nn . relu ( bias , name = scope . name ) if dropout : conv6 = tf . nn . dropout ( conv6 , 0.5 , seed = FLAGS . dropout seed ) with tf . variable scope ( 'conv7' ) as scope : kernel =  variable with weight decay ( 'weights' , shape = [ 5 , 5 , 192 , 192 ] , stddev = 0.0001 , wd = 0.0 ) conv = tf . nn . conv2d ( conv6 , kernel , [ 1 , 1 , 1 , 1 ] , padding = 'SAME' ) biases =  variable on cpu ( 'biases' , [ 192 ] , tf . constant initializer ( 0.1 ) ) bias = tf . nn . bias add ( conv , biases ) conv7 = tf . nn . relu ( bias , name = scope . name ) with tf . variable scope ( 'local1' ) as scope : reshape = tf . reshape ( conv7 , [ FLAGS . batch size , ( - 1 ) ] ) dim = reshape . get shape ( ) [ 1 ] . value weights =  variable with weight decay ( 'weights' , shape = [ dim , 192 ] , stddev = 0.05 , wd = 0 ) biases =  variable on cpu ( 'biases' , [ 192 ] , tf . constant initializer ( 0.1 ) ) local1 = tf . nn . relu ( ( tf . matmul ( reshape , weights ) + biases ) , name = scope . name ) with tf . variable scope ( 'local2' ) as scope : weights =  variable with weight decay ( 'weights' , shape = [ 192 , 192 ] , stddev = 0.05 , wd = 0 ) biases =  variable on cpu ( 'biases' , [ 192 ] , tf . constant initializer ( 0.1 ) ) local2 = tf . nn . relu ( ( tf . matmul ( local1 , weights ) + biases ) , name = scope . name ) if dropout : local2 = tf . nn . dropout ( local2 , 0.5 , seed = FLAGS . dropout seed ) with tf . variable scope ( 'softmax linear' ) as scope : weights =  variable with weight decay ( 'weights' , [ 192 , FLAGS . nb labels ] , stddev = 0.05 , wd = 0.0 ) biases =  variable on cpu ( 'biases' , [ FLAGS . nb labels ] , tf . constant initializer ( 0.0 ) ) logits = tf . add ( tf . matmul ( local2 , weights ) , biases , name = scope . name ) return logits 
def   Generate MS Build  Rule  Props  File  ( props path , msbuild rules ) : content = [ ' Project ' , { 'xmlns' : 'http://schemas.microsoft.com/developer/msbuild/2003' } ] for rule in msbuild rules : content . extend ( [ [ ' Property  Group ' , { ' Condition ' : ( "'$(%s)'  ==  ''  and  '$(%s)'  ==  ''  and  '$( Configuration  Type )'  !=  ' Makefile '" % ( rule . before targets , rule . after targets ) ) } , [ rule . before targets , ' Midl ' ] , [ rule . after targets , ' Custom  Build ' ] ] , [ ' Property  Group ' , [ rule . depends on , { ' Condition ' : "'$( Configuration  Type )'  !=  ' Makefile '" } , ( '  Selected  Files ;$(%s)' % rule . depends on ) ] ] , [ ' Item  Definition  Group ' , [ rule . rule name , [ ' Command  Line  Template ' , rule . command ] , [ ' Outputs ' , rule . outputs ] , [ ' Execution  Description ' , rule . description ] , [ ' Additional  Dependencies ' , rule . additional dependencies ] ] ] ] ) easy xml .  Write  Xml  If  Changed  ( content , props path , pretty =  True  , win32 =  True  ) 
def move by taskmap ( map , ** kwargs ) : def task name in map ( body , message ) : return map . get ( body [ u'task' ] ) return move ( task name in map , ** kwargs ) 
def coalesce table labels ( attributes , onrows , oncolumns ) : if ( ( not onrows ) or ( not oncolumns ) ) : onrows = ( onrows or [ ] ) oncolumns = ( oncolumns or [ ] ) if ( not onrows ) : onrows = [ attr for attr in attributes if ( attr not in oncolumns ) ] if ( not oncolumns ) : oncolumns = [ attr for attr in attributes if ( attr not in onrows ) ] return ( onrows , oncolumns ) 
def group ( seq , size ) : if ( not hasattr ( seq , 'next' ) ) : seq = iter ( seq ) while  True  : ( yield [ seq . next ( ) for i in xrange ( size ) ] ) 
def make or verify dir ( directory , mode = 493 , uid = 0 , strict =  False  ) : try : os . makedirs ( directory , mode ) except OS Error  as exception : if ( exception . errno == errno . EEXIST ) : if ( strict and ( not check permissions ( directory , mode , uid ) ) ) : raise errors .  Error  ( ( '%s  exists,  but  it  should  be  owned  by  user  %d  withpermissions  %s' % ( directory , uid , oct ( mode ) ) ) ) else : raise 
def patch signal ( ) : patch module ( 'signal' ) 
def will expire soon ( expiry ) : soon = ( timeutils . utcnow ( ) + datetime . timedelta ( seconds = 30 ) ) return ( expiry < soon ) 
def sample ( x , n , k = 0 ) : j = ( len ( x ) // n ) for   in range ( n ) : try : ( yield x [ k ] ) except  Index  Error  : break k += j 
def  validate endpoint ( endpoint , check native endpoint =  None  ) : if check native endpoint : check native endpoint ( endpoint ) elif ( not isinstance ( endpoint , dict ) ) : raise  Value  Error  ( "'endpoint'  must  be  a  dict" ) if isinstance ( endpoint , dict ) : if ( 'type' not in endpoint ) : raise  Value  Error  ( "'type'  required  in  endpoint  configuration" ) if ( endpoint [ 'type' ] not in [ 'tcp' , 'unix' ] ) : raise  Value  Error  ( 'invalid  type  "{}"  in  endpoint' . format ( endpoint [ 'type' ] ) ) for k in endpoint . keys ( ) : if ( k not in [ 'type' , 'host' , 'port' , 'path' , 'tls' ] ) : raise  Value  Error  ( " Invalid   key  '{}'  in  endpoint  configuration" . format ( k ) ) if ( endpoint [ 'type' ] == 'tcp' ) : for k in [ 'host' , 'port' ] : if ( k not in endpoint ) : raise  Value  Error  ( "'{}'  required  in  'tcp'  endpoint  config" . format ( k ) ) for k in [ 'path' ] : if ( k in endpoint ) : raise  Value  Error  ( "'{}'  not  valid  in  'tcp'  endpoint  config" . format ( k ) ) elif ( endpoint [ 'type' ] == 'unix' ) : for k in [ 'path' ] : if ( k not in endpoint ) : raise  Value  Error  ( "'{}'  required  for  'tcp'  endpoint  config" . format ( k ) ) for k in [ 'host' , 'port' , 'tls' ] : if ( k in endpoint ) : raise  Value  Error  ( "'{}'  not  valid  for  in  'tcp'  endpoint  config" . format ( k ) ) else : assert  False  , 'should  not  arrive  here' 
def  config getter ( get opt , key , value regex =  None  , cwd =  None  , user =  None  , password =  None  , ignore retcode =  False  , ** kwargs ) : kwargs = salt . utils . clean kwargs ( ** kwargs ) global  = kwargs . pop ( 'global' ,  False  ) if kwargs : salt . utils . invalid kwargs ( kwargs ) if ( cwd is  None  ) : if ( not global  ) : raise  Salt  Invocation  Error  ( "'cwd'  argument  required  unless  global= True " ) else : cwd =  expand path ( cwd , user ) if ( get opt == '--get-regexp' ) : if ( ( value regex is not  None  ) and ( not isinstance ( value regex , six . string types ) ) ) : value regex = str ( value regex ) else : value regex =  None  command = [ 'git' , 'config' ] command . extend (  which git config ( global  , cwd , user , password ) ) command . append ( get opt ) command . append ( key ) if ( value regex is not  None  ) : command . append ( value regex ) return  git run ( command , cwd = cwd , user = user , password = password , ignore retcode = ignore retcode , failhard =  False  ) 
def  do mb search ( entity , query = '' , fields = { } , limit =  None  , offset =  None  , strict =  False  ) : query parts = [ ] if query : clean query = util .  unicode ( query ) if fields : clean query = re . sub ( LUCENE SPECIAL , '\\\\\\1' , clean query ) if strict : query parts . append ( ( '"%s"' % clean query ) ) else : query parts . append ( clean query . lower ( ) ) else : query parts . append ( clean query ) for ( key , value ) in fields . items ( ) : if ( key not in VALID SEARCH FIELDS [ entity ] ) : raise  Invalid  Search  Field  Error  ( ( '%s  is  not  a  valid  search  field  for  %s' % ( key , entity ) ) ) elif ( key == 'puid' ) : warn ( "PUID  support  was  removed  from  server\nthe  'puid'  field  is  ignored" ,  Warning  , stacklevel = 2 ) value = util .  unicode ( value ) value = re . sub ( LUCENE SPECIAL , '\\\\\\1' , value ) if value : if strict : query parts . append ( ( '%s:"%s"' % ( key , value ) ) ) else : value = value . lower ( ) query parts . append ( ( '%s:(%s)' % ( key , value ) ) ) if strict : full query = '  AND  ' . join ( query parts ) . strip ( ) else : full query = '  ' . join ( query parts ) . strip ( ) if ( not full query ) : raise  Value  Error  ( 'at  least  one  query  term  is  required' ) params = { 'query' : full query } if limit : params [ 'limit' ] = str ( limit ) if offset : params [ 'offset' ] = str ( offset ) return  do mb query ( entity , '' , [ ] , params ) 
def basename from filename ( filename ) : mimetype = mimetypes . guess type ( filename ) [ 0 ] if ( mimetype is not  None  ) : mimetype = mimetype . lower ( ) for ( filetype , icon name ) in KNOWN FILE MIME TYPES : if ( filetype in mimetype ) : return icon name extension = os . path . splitext ( filename ) [ 1 ] return KNOWN FILE EXTENSIONS . get ( extension . lower ( ) , u'file-text.svg' ) 
def allequal ( seq ) : if ( len ( seq ) < 2 ) : return  True  val = seq [ 0 ] for i in xrange ( 1 , len ( seq ) ) : thisval = seq [ i ] if ( thisval != val ) : return  False  return  True  
def simple preprocess ( doc , deacc =  False  , min len = 2 , max len = 15 ) : tokens = [ token for token in tokenize ( doc , lower =  True  , deacc = deacc , errors = 'ignore' ) if ( ( min len <= len ( token ) <= max len ) and ( not token . startswith ( ' ' ) ) ) ] return tokens 
def get New  Derivation  ( element Node  , prefix , side Length  ) : return evaluate .  Empty  Object  ( ) 
def  write config ( config ) : try : with salt . utils . atomicfile . atomic open ( '/usbkey/config' , 'w' ) as config file : config file . write ( '#\n#   This   file  was  generated  by  salt\n#\n' ) for prop in  Ordered  Dict  ( sorted ( config . items ( ) ) ) : if ( '  ' in str ( config [ prop ] ) ) : if ( ( not config [ prop ] . startswith ( '"' ) ) or ( not config [ prop ] . endswith ( '"' ) ) ) : config [ prop ] = '"{0}"' . format ( config [ prop ] ) config file . write ( '{0}={1}\n' . format ( prop , config [ prop ] ) ) log . debug ( 'smartos.config  -  wrote  /usbkey/config:  {0}' . format ( config ) ) except IO Error  : return  False  return  True  
def compile fnclex ( context ) : codegen = context . codegen ( ) library = codegen . create library ( 'kb982107' ) ir mod = '\ndefine  void  @fnclex()  {\n    call  void  asm  sideeffect  "fnclex",  ""()\n    ret  void\n}\n        ' ll . initialize native asmparser ( ) library . add llvm module ( ll . parse assembly ( ir mod ) ) library . finalize ( ) return library 
def standalone html page for models ( models , resources , title ) : return file html ( models , resources , title ) 
def get language objects ( site id =  None  ) : return list ( get languages ( site id ) ) 
def get images table ( meta ) : images =  Table  ( 'images' , meta ,  Column  ( 'id' ,  Integer  ( ) , primary key =  True  , nullable =  False  ) ,  Column  ( 'name' ,  String  ( 255 ) ) ,  Column  ( 'disk format' ,  String  ( 20 ) ) ,  Column  ( 'container format' ,  String  ( 20 ) ) ,  Column  ( 'size' ,  Integer  ( ) ) ,  Column  ( 'status' ,  String  ( 30 ) , nullable =  False  ) ,  Column  ( 'is public' ,  Boolean  ( ) , nullable =  False  , default =  False  , index =  True  ) ,  Column  ( 'location' ,  Text  ( ) ) ,  Column  ( 'created at' ,  Date  Time  ( ) , nullable =  False  ) ,  Column  ( 'updated at' ,  Date  Time  ( ) ) ,  Column  ( 'deleted at' ,  Date  Time  ( ) ) ,  Column  ( 'deleted' ,  Boolean  ( ) , nullable =  False  , default =  False  , index =  True  ) ,  Column  ( 'checksum' ,  String  ( 32 ) ) ,  Column  ( 'owner' ,  String  ( 255 ) ) ,  Column  ( 'min disk' ,  Integer  ( ) , default = 0 ) ,  Column  ( 'min ram' ,  Integer  ( ) , default = 0 ) , mysql engine = ' Inno DB' , extend existing =  True  ) return images 
@ api versions . wraps ( '2.10' ) @ utils . arg ( 'keypair' , metavar = '<keypair>' , help =   ( ' Name   of  keypair.' ) ) @ utils . arg ( '--user' , metavar = '<user-id>' , default =  None  , help =   ( 'ID  of  key-pair  owner  ( Admin   only).' ) ) def do keypair show ( cs , args ) : keypair = cs . keypairs . get ( args . keypair , args . user )  print keypair ( keypair ) 
def get time server ( ) : ret = salt . utils . mac utils . execute return result ( 'systemsetup  -getnetworktimeserver' ) return salt . utils . mac utils . parse return ( ret ) 
def  Document  ( docx =  None  ) : docx = (  default docx path ( ) if ( docx is  None  ) else docx ) document part =  Package  . open ( docx ) . main document part if ( document part . content type != CT . WML DOCUMENT MAIN ) : tmpl = "file  '%s'  is  not  a   Word   file,  content  type  is  '%s'" raise  Value  Error  ( ( tmpl % ( docx , document part . content type ) ) ) return document part . document 
def  Stringify JSON ( item ) : if isinstance ( item , ( tuple , list ) ) : return [  Stringify JSON ( x ) for x in item ] elif isinstance ( item , dict ) : result = { } for ( k , v ) in item . items ( ) : result [ k ] =  Stringify JSON ( v ) return result elif ( type ( item ) in ( int , long , float , bool ) ) : return item elif ( item is  None  ) : return  None  else : return utils .  Smart  Unicode  ( item ) 
def   virtual   ( ) : if HAS CX ORACLE : return   virtualname   return (  False  , ' The   oracle  execution  module  not  loaded:  python  oracle  library  not  found.' ) 
def aes cbc decrypt ( data , key , iv ) : expanded key = key expansion ( key ) block count = int ( ceil ( ( float ( len ( data ) ) / BLOCK SIZE BYTES ) ) ) decrypted data = [ ] previous cipher block = iv for i in range ( block count ) : block = data [ ( i * BLOCK SIZE BYTES ) : ( ( i + 1 ) * BLOCK SIZE BYTES ) ] block += ( [ 0 ] * ( BLOCK SIZE BYTES - len ( block ) ) ) decrypted block = aes decrypt ( block , expanded key ) decrypted data += xor ( decrypted block , previous cipher block ) previous cipher block = block decrypted data = decrypted data [ : len ( data ) ] return decrypted data 
def xattr writes supported ( path ) : try : import xattr except  Import  Error  : return  False  def set xattr ( path , key , value ) : xattr . setxattr ( path , ( 'user.%s' % key ) , value ) fake filepath = os . path . join ( path , 'testing-checkme' ) result =  True  with open ( fake filepath , 'wb' ) as fake file : fake file . write ( 'XXX' ) fake file . flush ( ) try : set xattr ( fake filepath , 'hits' , '1' ) except IO Error  as e : if ( e . errno == errno . EOPNOTSUPP ) : result =  False  else : if os . path . exists ( fake filepath ) : os . unlink ( fake filepath ) return result 
def inception v4 ( inputs , num classes = 1001 , is training =  True  , dropout keep prob = 0.8 , reuse =  None  , scope = ' Inception V4' , create aux logits =  True  ) : end points = { } with tf . variable scope ( scope , ' Inception V4' , [ inputs ] , reuse = reuse ) as scope : with slim . arg scope ( [ slim . batch norm , slim . dropout ] , is training = is training ) : ( net , end points ) = inception v4 base ( inputs , scope = scope ) with slim . arg scope ( [ slim . conv2d , slim . max pool2d , slim . avg pool2d ] , stride = 1 , padding = 'SAME' ) : if create aux logits : with tf . variable scope ( ' Aux  Logits ' ) : aux logits = end points [ ' Mixed  6h' ] aux logits = slim . avg pool2d ( aux logits , [ 5 , 5 ] , stride = 3 , padding = 'VALID' , scope = ' Avg  Pool  1a 5x5' ) aux logits = slim . conv2d ( aux logits , 128 , [ 1 , 1 ] , scope = ' Conv 2d 1b 1x1' ) aux logits = slim . conv2d ( aux logits , 768 , aux logits . get shape ( ) [ 1 : 3 ] , padding = 'VALID' , scope = ' Conv 2d 2a' ) aux logits = slim . flatten ( aux logits ) aux logits = slim . fully connected ( aux logits , num classes , activation fn =  None  , scope = ' Aux  logits' ) end points [ ' Aux  Logits ' ] = aux logits with tf . variable scope ( ' Logits ' ) : net = slim . avg pool2d ( net , net . get shape ( ) [ 1 : 3 ] , padding = 'VALID' , scope = ' Avg  Pool  1a' ) net = slim . dropout ( net , dropout keep prob , scope = ' Dropout  1b' ) net = slim . flatten ( net , scope = ' Pre  Logits  Flatten ' ) end points [ ' Pre  Logits  Flatten ' ] = net logits = slim . fully connected ( net , num classes , activation fn =  None  , scope = ' Logits ' ) end points [ ' Logits ' ] = logits end points [ ' Predictions ' ] = tf . nn . softmax ( logits , name = ' Predictions ' ) return ( logits , end points ) 
def get all queues ( ) : redis conn =  connect ( ) prefix =  get queue name prefix ( ) return [ q for q in rq .  Queue  . all ( connection = redis conn ) if q . name . startswith ( prefix ) ] 
def validate and find master dns ( session , parsed globals , cluster id ) : cluster state = emrutils . get cluster state ( session , parsed globals , cluster id ) if ( cluster state in constants . TERMINATED STATES ) : raise exceptions .  Cluster  Terminated  Error  emr = emrutils . get client ( session , parsed globals ) try : cluster running waiter = emr . get waiter ( 'cluster running' ) if ( cluster state in constants . STARTING STATES ) : print ' Waiting   for  the  cluster  to  start.' cluster running waiter . wait (  Cluster  Id  = cluster id ) except  Waiter  Error  : raise exceptions .  Master DNS Not  Available  Error  return emrutils . find master dns ( session = session , cluster id = cluster id , parsed globals = parsed globals ) 
def do unpickle ( data ) : return loads ( to str ( data ) ) 
def get encoding from headers ( headers ) : content type = headers . get ( 'content-type' ) if ( not content type ) : return  None  ( content type , params ) = cgi . parse header ( content type ) if ( 'charset' in params ) : return params [ 'charset' ] . strip ( '\'"' ) if ( 'text' in content type ) : return 'ISO-8859-1' return  None  
def create pipeline ( name , unique id , description = '' , region =  None  , key =  None  , keyid =  None  , profile =  None  ) : client =  get client ( region , key , keyid , profile ) r = { } try : response = client . create pipeline ( name = name , unique Id  = unique id , description = description ) r [ 'result' ] = response [ 'pipeline Id ' ] except ( botocore . exceptions .  Boto  Core  Error  , botocore . exceptions .  Client  Error  ) as e : r [ 'error' ] = str ( e ) return r 
def is storage local ( storage ) : try : storage . path ( 'test' ) except  Not  Implemented  Error  : return  False  return  True  
@ bdd . then ( bdd . parsers . parse ( ' The   session  should  look  like:\n{expected}' ) ) def compare session ( request , quteproc , expected ) : quteproc . compare session ( expected ) 
def load ( path ) : if ( not os . path . isfile ( path ) ) : logger . info ( u' File   does  not  exist:  %s' , path ) return { } try : with gzip . open ( path , u'rb' ) as fp : return json . load ( fp , object hook = models . model json decoder ) except ( IO Error  ,  Value  Error  ) as error : logger . warning ( u' Loading   JSON  failed:  %s' , encoding . locale decode ( error ) ) return { } 
def lower bound ( w dyad ) : assert is dyad weight ( w dyad ) md = get max denom ( w dyad ) lb1 = ( len ( bin ( md ) ) - 3 ) lb2 = ( sum ( ( ( 1 if ( e != 0 ) else 0 ) for e in w dyad ) ) - 1 ) return max ( lb1 , lb2 ) 
def list compatible ( ) : workflows = get compatible ( ) feedback = alfred .  Feedback  ( ) for w in workflows : subtitle = ( ( ( 'v' + unicode ( w . version ) ) + '  ' ) + w . description ) feedback . add Item  ( title = w . name , subtitle = subtitle , icon = w . icon , valid = 'no' ) if feedback . is Empty  ( ) : feedback . add Item  ( title = ' No   compatible  workflows  found' , valid = 'no' , autocomplete = '' ) else : feedback . add Item  ( title = ' Go   back' , valid = 'no' , icon = 'back.png' , autocomplete = '' ) feedback . output ( ) 
def  Get  Indices  (  app =  None  ) : req = api base pb .  String  Proto  ( ) req . set value ( datastore types .  Resolve  App  Id  (  app ) ) resp = datastore pb .  Composite  Indices  ( ) resp =   Call  ( ' Get  Indices ' , req , resp ) return resp . index list ( ) 
def referer str ( request ) : referrer = request . headers . get ( ' Referer ' ) if ( referrer is  None  ) : return referrer return to native str ( referrer , errors = 'replace' ) 
def min path ( path ) : ( path , ext ) = os . path . splitext ( path ) return ( ( path + '.min' ) + ext ) 
def actions get ( context , uuid ) : return IMPL . actions get ( context , uuid ) 
def generate certificates ( base dir ) : keys dir = os . path . join ( base dir , 'certificates' ) public keys dir = os . path . join ( base dir , 'public keys' ) secret keys dir = os . path . join ( base dir , 'private keys' ) for d in [ keys dir , public keys dir , secret keys dir ] : if os . path . exists ( d ) : shutil . rmtree ( d ) os . mkdir ( d ) ( server public file , server secret file ) = zmq . auth . create certificates ( keys dir , 'server' ) ( client public file , client secret file ) = zmq . auth . create certificates ( keys dir , 'client' ) for key file in os . listdir ( keys dir ) : if key file . endswith ( '.key' ) : shutil . move ( os . path . join ( keys dir , key file ) , os . path . join ( public keys dir , '.' ) ) for key file in os . listdir ( keys dir ) : if key file . endswith ( '.key secret' ) : shutil . move ( os . path . join ( keys dir , key file ) , os . path . join ( secret keys dir , '.' ) ) 
def get user ( user name =  None  , region =  None  , key =  None  , keyid =  None  , profile =  None  ) : conn =  get conn ( region = region , key = key , keyid = keyid , profile = profile ) try : info = conn . get user ( user name ) if ( not info ) : return  False  return info except boto . exception .  Boto  Server  Error  as e : log . debug ( e ) msg = ' Failed   to  get  user  {0}  info.' log . error ( msg . format ( user name ) ) return  False  
def process Append  Element  Node  ( archivable Objects  , element Node  , parent Node  ) : if ( element Node  ==  None  ) : return object = element Node  . get First  Child  By  Local  Name  ( 'object' ) if ( 'bf:type' not in object . attributes ) : return shape Type  = object . attributes [ 'bf:type' ] if ( shape Type  not in global Carvable  Class  Object  Table  ) : return carvable Class  Object  = global Carvable  Class  Object  Table  [ shape Type  ] archivable Object  = get Carvable  Object  ( element Node  , carvable Class  Object  , object ) archivable Object  . element Node  . attributes [ 'visible' ] = element Node  . attributes [ 'visible' ] archivable Object  . set To  Art  Of  Illusion  Dictionary  ( ) archivable Object  . element Node  . parent Node  = parent Node  archivable Objects  . append ( archivable Object  ) 
def test api key ( ) : @ hug . authentication . api key def api key authentication ( api key ) : if ( api key == ' Bacon ' ) : return ' Timothy ' @ hug . get ( requires = api key authentication ) def hello world ( ) : return ' Hello   world!' assert ( hug . test . get ( api , 'hello world' , headers = { 'X- Api - Key ' : ' Bacon ' } ) . data == ' Hello   world!' ) assert ( '401' in hug . test . get ( api , 'hello world' ) . status ) assert ( '401' in hug . test . get ( api , 'hello world' , headers = { 'X- Api - Key ' : ' Invalid ' } ) . status ) 
def text param ( registry , xml parent , data ) : base param ( registry , xml parent , data ,  True  , 'hudson.model. Text  Parameter  Definition ' ) 
def  mangle attr ( name ) : return ( 'm ' + name ) 
def arity ( rel ) : if ( len ( rel ) == 0 ) : return 0 return len ( list ( rel ) [ 0 ] ) 
def compute known facts ( known facts , known facts keys ) : from textwrap import dedent , wrap fact string = dedent ( '        """\n         The   contents  of  this  file  are  the  return  value  of\n        ``sympy.assumptions.ask.compute known facts``.\n\n         Do   NOT  manually  edit  this  file.\n         Instead ,  run  ./bin/ask update.py.\n        """\n\n        from  sympy.core.cache  import  cacheit\n        from  sympy.logic.boolalg  import   And ,   Not ,   Or \n        from  sympy.assumptions.ask  import  Q\n\n        #  -{   Known   facts  in   Conjunctive    Normal    Form   }-\n        @cacheit\n        def  get known facts cnf():\n                return   And (\n                        %s\n                )\n\n        #  -{   Known   facts  in  compressed  sets  }-\n        @cacheit\n        def  get known facts dict():\n                return  {\n                        %s\n                }\n        ' ) LINE = ',\n                ' HANG = ( '  ' * 8 ) cnf = to cnf ( known facts ) c = LINE . join ( [ str ( a ) for a in cnf . args ] ) mapping = single fact lookup ( known facts keys , cnf ) items = sorted ( mapping . items ( ) , key = str ) keys = [ str ( i [ 0 ] ) for i in items ] values = [ ( 'set(%s)' % sorted ( i [ 1 ] , key = str ) ) for i in items ] m = ( LINE . join ( [ '\n' . join ( wrap ( ( '%s:  %s' % ( k , v ) ) , subsequent indent = HANG , break long words =  False  ) ) for ( k , v ) in zip ( keys , values ) ] ) + ',' ) return ( fact string % ( c , m ) ) 
@ handle response format @ treeio login required def account view ( request , account id , response format = 'html' ) : account = get object or 404 (  Account  , pk = account id ) return render to response ( 'finance/account view' , { 'account' : account } , context instance =  Request  Context  ( request ) , response format = response format ) 
def main ( ) : defaults = { 'TEST STACK' : str (  Google  Http  Load  Balancer  Test  Scenario  . DEFAULT TEST ID ) , 'TEST APP' : ( 'gcphttplbtest' +  Google  Http  Load  Balancer  Test  Scenario  . DEFAULT TEST ID ) } return citest . base .  Test  Runner  . main ( parser inits = [  Google  Http  Load  Balancer  Test  Scenario  . init Argument  Parser  ] , default binding overrides = defaults , test case list = [  Google  Http  Load  Balancer  Test  ] ) 
def filter factory ( global conf , ** local conf ) : conf = global conf . copy ( ) conf . update ( local conf ) register swift info ( 'formpost' ) return ( lambda app :  Form  Post  ( app , conf ) ) 
def requires parallel ( task ) : return ( ( state . env . parallel and ( not getattr ( task , 'serial' ,  False  ) ) ) or getattr ( task , 'parallel' ,  False  ) ) 
def maybe future ( x ) : if is future ( x ) : return x else : fut =  Future  ( ) fut . set result ( x ) return fut 
